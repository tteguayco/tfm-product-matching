{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Data Preparation</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "# Force Garbage Collector to realease unreferenced memory\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Brand</th>\n",
       "      <th>Model</th>\n",
       "      <th>Price</th>\n",
       "      <th>Currency</th>\n",
       "      <th>Color</th>\n",
       "      <th>MatchingCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>leifheit kleidersack lang farbe schwarz</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.99</td>\n",
       "      <td>EUR</td>\n",
       "      <td>schwarz</td>\n",
       "      <td>295639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>leifheit kleidersack lang farbe schwarz</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.99</td>\n",
       "      <td>EUR</td>\n",
       "      <td>schwarz</td>\n",
       "      <td>295639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>leifheit kleidersack lang farbe schwarz</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.99</td>\n",
       "      <td>EUR</td>\n",
       "      <td>schwarz</td>\n",
       "      <td>295639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>leifheit kleidersack lang farbe schwarz</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.99</td>\n",
       "      <td>EUR</td>\n",
       "      <td>schwarz</td>\n",
       "      <td>295639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>leifheit kleidersack lang farbe schwarz</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.99</td>\n",
       "      <td>EUR</td>\n",
       "      <td>schwarz</td>\n",
       "      <td>295639</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Title Brand Model  Price Currency  \\\n",
       "0  leifheit kleidersack lang farbe schwarz   NaN   NaN  14.99      EUR   \n",
       "1  leifheit kleidersack lang farbe schwarz   NaN   NaN  14.99      EUR   \n",
       "2  leifheit kleidersack lang farbe schwarz   NaN   NaN  14.99      EUR   \n",
       "3  leifheit kleidersack lang farbe schwarz   NaN   NaN  14.99      EUR   \n",
       "4  leifheit kleidersack lang farbe schwarz   NaN   NaN  14.99      EUR   \n",
       "\n",
       "     Color  MatchingCode  \n",
       "0  schwarz        295639  \n",
       "1  schwarz        295639  \n",
       "2  schwarz        295639  \n",
       "3  schwarz        295639  \n",
       "4  schwarz        295639  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "DATASET_FILEPATH = \"../_data/StructuredSmartPhonesDataset.csv\"\n",
    "\n",
    "df = pd.read_csv(DATASET_FILEPATH, header=0, sep=\",\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial shape of dataset: (50000, 7)\n",
      "Final shape of dataset: (10000, 6)\n",
      "\n",
      "Number of unique classes (MatchingCode): 214\n",
      "Number of unique rows: 1517\n"
     ]
    }
   ],
   "source": [
    "print(\"Initial shape of dataset: {}\".format(df.shape))\n",
    "\n",
    "# Drop non-relevant columns for classification\n",
    "df = df.drop(columns=[\"Title\"])\n",
    "\n",
    "# Remove rows with NULL values\n",
    "df = df.dropna()\n",
    "\n",
    "# Limit number of rows\n",
    "df = df.head(10000)\n",
    "\n",
    "print(\"Final shape of dataset: {}\".format(df.shape))\n",
    "\n",
    "n_unique_classes = len(set(df[\"MatchingCode\"].values))\n",
    "n_unique_rows = df.drop_duplicates().shape[0]\n",
    "\n",
    "print(\"\\nNumber of unique classes (MatchingCode): {}\".format(n_unique_classes))\n",
    "print(\"Number of unique rows: {}\".format(n_unique_rows))\n",
    "\n",
    "# Export processed dataset to file\n",
    "df.to_csv(\"../_data/StructuredSmartPhonesDatasetCleaned.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of One-Hot-Encoded dataset: (10000, 1210)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "X = df.drop(columns=[\"MatchingCode\"])\n",
    "y = df[\"MatchingCode\"].values\n",
    "\n",
    "# Codify string variables with OneHot encoding\n",
    "enc = OneHotEncoder()\n",
    "enc.fit(X)\n",
    "X_encoded = enc.transform(X)\n",
    "\n",
    "print(\"Shape of One-Hot-Encoded dataset: {}\".format(X_encoded.shape))\n",
    "\n",
    "# Train and test sets are stratified, i.e. they both contain the same proportion of classes than the original set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>K Nearest Neighbours</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tegua\\AppData\\Local\\Programs\\Python\\Python37-32\\lib\\site-packages\\sklearn\\model_selection\\_split.py:652: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=4.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Search for k-NN took 135.514 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 4, 'weights': 'distance'}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import time\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# Perform a Grid Search to find the best values for the hyperparameters (k and weights)\n",
    "# using Cross Validation with 4 stratified partitions\n",
    "param_grid = {\n",
    "    \"n_neighbors\": range(1, 11),\n",
    "    \"weights\": [\"uniform\", \"distance\"]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(knn, param_grid=param_grid, cv=4)\n",
    "\n",
    "start_time = time.time()\n",
    "grid_search.fit(X_train, y_train)\n",
    "finish_time = time.time()\n",
    "\n",
    "print(\"Grid Search for k-NN took {} seconds.\".format(round(finish_time - start_time, 3)))\n",
    "\n",
    "mean_scores = grid_search.cv_results_[\"mean_test_score\"]\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best values for the k-NN hyperparameters: k = 4, weights = distance\n"
     ]
    }
   ],
   "source": [
    "best_k = best_params[\"n_neighbors\"]\n",
    "best_weights = best_params[\"weights\"]\n",
    "\n",
    "print(\"Best values for the k-NN hyperparameters: k = {}, weights = {}\".format(best_k, best_weights))\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=best_k, weights=best_weights)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "y_pred = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 92.95\n",
      "Number of instances correctly classified: 1859/2000\n",
      "Number of instances incorrectly classified: 141/2000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "total_ins = len(y_pred)\n",
    "n_pred_ok = np.sum(y_test == y_pred)\n",
    "n_pred_ko = total_ins - n_pred_ok\n",
    "acc = n_pred_ok / total_ins * 100\n",
    "\n",
    "print(\"Accuracy: {}\".format(acc))\n",
    "print(\"Number of instances correctly classified: {}/{}\".format(n_pred_ok, total_ins))\n",
    "print(\"Number of instances incorrectly classified: {}/{}\".format(n_pred_ko, total_ins))\n",
    "\n",
    "# inspect instances incorrecly classified (some \"head\", for example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Support Vector Machines</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tegua\\AppData\\Local\\Programs\\Python\\Python37-32\\lib\\site-packages\\sklearn\\model_selection\\_split.py:652: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=4.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "C:\\Users\\tegua\\AppData\\Local\\Programs\\Python\\Python37-32\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Search for SVM took 1443.44 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C': 470.79411276428084, 'gamma': 8.890128936232237e-06}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn import svm\n",
    "from scipy.stats import uniform as sp_rand\n",
    "from time import time\n",
    "\n",
    "svm_clf = svm.SVC()\n",
    "\n",
    "# Perform a Random Search to find the best values for the hyperparameters (C and gamma)\n",
    "# using Cross Validation with 4 stratified partitions.\n",
    "# n_iter_search random parameter settings are chosen to perform CV\n",
    "param_rand = {\n",
    "    \"C\": sp_rand(loc=1, scale=500), \n",
    "    \"gamma\": sp_rand(loc=1e-9, scale=1e-5)\n",
    "}\n",
    "\n",
    "n_iter_search = 20\n",
    "random_search = RandomizedSearchCV(svm_clf, param_distributions=param_rand, n_iter=n_iter_search, cv=4)\n",
    "\n",
    "start_time = time()\n",
    "random_search.fit(X_train, y_train)\n",
    "finish_time = time()\n",
    "\n",
    "print(\"Random Search for SVM took {} seconds.\".format(round(finish_time - start_time, 3)))\n",
    "\n",
    "mean_scores = random_search.cv_results_[\"mean_test_score\"]\n",
    "best_params = random_search.best_params_\n",
    "\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best values for the SVM hyperparameters: C = 470.79411276428084, gamma = 8.890128936232237e-06\n"
     ]
    }
   ],
   "source": [
    "best_C = best_params[\"C\"]\n",
    "best_gamma = best_params[\"gamma\"]\n",
    "\n",
    "print(\"Best values for the SVM hyperparameters: C = {}, gamma = {}\".format(best_C, best_gamma))\n",
    "\n",
    "svm_clf = svm.SVC(C=best_C, gamma=best_gamma, probability=True)\n",
    "svm_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = svm_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 34.849999999999994\n",
      "Number of instances correctly classified: 697/2000\n",
      "Number of instances incorrectly classified: 1303/2000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "total_ins = len(y_pred)\n",
    "n_pred_ok = np.sum(y_test == y_pred)\n",
    "n_pred_ko = total_ins - n_pred_ok\n",
    "acc = n_pred_ok / total_ins * 100\n",
    "\n",
    "print(\"Accuracy: {}\".format(acc))\n",
    "print(\"Number of instances correctly classified: {}/{}\".format(n_pred_ok, total_ins))\n",
    "print(\"Number of instances incorrectly classified: {}/{}\".format(n_pred_ko, total_ins))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Logistic regression</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tegua\\AppData\\Local\\Programs\\Python\\Python37-32\\lib\\site-packages\\sklearn\\model_selection\\_split.py:652: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=4.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "C:\\Users\\tegua\\AppData\\Local\\Programs\\Python\\Python37-32\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\tegua\\AppData\\Local\\Programs\\Python\\Python37-32\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\tegua\\AppData\\Local\\Programs\\Python\\Python37-32\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Search for Logistic Regression took 464.122 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C': 1291.5496650148827, 'penalty': 'l2'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from sklearn import linear_model, datasets\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "lr_clf = linear_model.LogisticRegression()\n",
    "\n",
    "# Perform a Grid Search to find the best values for the hyperparameters (penalty and C)\n",
    "# using Cross Validation with 4 stratified partitions.\n",
    "param_grid = {\n",
    "    \"penalty\": ['l1', 'l2'],\n",
    "    \"C\": np.logspace(0, 4, 10)\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(lr_clf, param_grid, cv=4)\n",
    "\n",
    "start_time = time.time()\n",
    "grid_search.fit(X_train, y_train)\n",
    "finish_time = time.time()\n",
    "\n",
    "print(\"Grid Search for Logistic Regression took {} seconds.\".format(round(finish_time - start_time, 3)))\n",
    "\n",
    "mean_scores = grid_search.cv_results_[\"mean_test_score\"]\n",
    "best_params = grid_search.best_params_\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best values for the Logistic Regression hyperparameters: penalty = l2, C = 1291.5496650148827\n"
     ]
    }
   ],
   "source": [
    "best_penalty = best_params[\"penalty\"]\n",
    "best_C = best_params[\"C\"]\n",
    "\n",
    "print(\"Best values for the Logistic Regression hyperparameters: penalty = {}, C = {}\".format(best_penalty, best_C))\n",
    "\n",
    "lr_clf = linear_model.LogisticRegression(penalty=best_penalty, C=best_C)\n",
    "lr_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lr_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 93.0\n",
      "Number of instances correctly classified: 1860/2000\n",
      "Number of instances incorrectly classified: 140/2000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "total_ins = len(y_pred)\n",
    "n_pred_ok = np.sum(y_test == y_pred)\n",
    "n_pred_ko = total_ins - n_pred_ok\n",
    "acc = n_pred_ok / total_ins * 100\n",
    "\n",
    "print(\"Accuracy: {}\".format(acc))\n",
    "print(\"Number of instances correctly classified: {}/{}\".format(n_pred_ok, total_ins))\n",
    "print(\"Number of instances incorrectly classified: {}/{}\".format(n_pred_ko, total_ins))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Random Forest</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Search for Random Forest took 9.565 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 7}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf = RandomForestRegressor()\n",
    "\n",
    "# Perform Grid Search on number of trees (n_estimators)\n",
    "param_grid = {\n",
    "    'n_estimators': range(1, 10)\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(rf, param_grid=param_grid, cv=4)\n",
    "\n",
    "start_time = time.time()\n",
    "grid_search.fit(X_train, y_train)\n",
    "finish_time = time.time()\n",
    "\n",
    "print(\"Grid Search for Random Forest took {} seconds.\".format(round(finish_time - start_time, 3)))\n",
    "\n",
    "mean_scores = grid_search.cv_results_[\"mean_test_score\"]\n",
    "best_params = grid_search.best_params_\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_n_estimators = best_params[\"n_estimators\"]\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=best_n_estimators)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 81.75\n",
      "Number of instances correctly classified: 1635/2000\n",
      "Number of instances incorrectly classified: 365/2000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "total_ins = len(y_pred)\n",
    "n_pred_ok = np.sum(y_test == y_pred)\n",
    "n_pred_ko = total_ins - n_pred_ok\n",
    "acc = n_pred_ok / total_ins * 100\n",
    "\n",
    "print(\"Accuracy: {}\".format(acc))\n",
    "print(\"Number of instances correctly classified: {}/{}\".format(n_pred_ok, total_ins))\n",
    "print(\"Number of instances incorrectly classified: {}/{}\".format(n_pred_ko, total_ins))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
